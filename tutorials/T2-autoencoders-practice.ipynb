{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurosur workshop 2021\n",
    "\n",
    "## Tutorial 2 - Autoencoders\n",
    "#### Creator: Manos Theodosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tutorial objectives\n",
    "\n",
    "In this notebook we will learn a few things about autoencoders\n",
    "- Implement a linear autoencoder and contrast it with PCA.\n",
    "- Implement a nonlinear (and sparse) autoencoder.\n",
    "- Implement a deep autoencoder.\n",
    "- Compare the different autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports and helper functtions\n",
    "\n",
    "Execute the following cells that import packages needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "plt.set_cmap(\"gray\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchsummary\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.datasets as ds\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_mnist(datadir=\"./data_cache\"):\n",
    "    train_ds = ds.MNIST(root=datadir, train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                             ]))\n",
    "    test_ds = ds.MNIST(root=datadir, train=False, download=True, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                             ]))\n",
    "    def to_xy(dataset):\n",
    "        Y = dataset.targets.long()\n",
    "        X = dataset.data.view(dataset.data.shape[0], -1) / 255.0\n",
    "        return X, Y\n",
    "\n",
    "    X_tr, Y_tr = to_xy(train_ds)\n",
    "    X_te, Y_te = to_xy(test_ds)\n",
    "    mean = X_tr.mean(dim=0)\n",
    "    X_tr -= mean\n",
    "    X_te -= mean\n",
    "    return X_tr, Y_tr, X_te, Y_te\n",
    "\n",
    "def make_loader(dataset, batch_size=128, num_workers=4):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Linear autoencoders\n",
    "\n",
    "As we've seen, autoencoders map us from the data domain to a latent representation. For this exercise, we will create a linear autoencoder and we will compare the latent representation with that of PCA.\n",
    "\n",
    "### 1.1 Create the `LinearAutoencoder` class\n",
    "In the next cell, fill in the code for the linear autoencoder.\n",
    "\n",
    "**Note**: for this class, we will not include learnable biases in the linear layers, in order to be able to compare and contrast with PCA. Feel free to experiment with adding biases to this class, or removing them from the rest of the classes we will create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        latent_size,\n",
    "    ):\n",
    "        super(LinearAutoencoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        # create the encoder and the decoder\n",
    "        self.encoder = ...\n",
    "        self.decoder = ...\n",
    "\n",
    "    def forward(self, data):\n",
    "        # encode the input to the latent space\n",
    "        latent = ...\n",
    "        \n",
    "        # decode the latent representation back into the input space\n",
    "        recons = ...\n",
    "        return recons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load MNIST\n",
    "Let's load MNIST using the provided `load_mnist()` function and keep $5,000$ images to train our autoencoder. When creating data loaders, use a batch size of $256$ (to make training faster). Let's also visualize some of the data to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load MNIST and keep a subset\n",
    "X_tr, Y_tr, X_te, Y_te = load_mnist()\n",
    "\n",
    "num_train = 5000\n",
    "indexes = ...\n",
    "\n",
    "X_tr = X_tr[indexes]\n",
    "Y_tr = Y_tr[indexes]\n",
    "\n",
    "# generate loaders\n",
    "batch_size = 256\n",
    "train_dl = make_loader(TensorDataset(X_tr, Y_tr), batch_size=batch_size)\n",
    "test_dl = make_loader(TensorDataset(X_te, Y_te), batch_size=batch_size)\n",
    "\n",
    "# plot some of the data\n",
    "indexes_train = ...\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create a model\n",
    "We will now create a model from the `LinearAutoencoder` class that we defined, and we'll print the summary in order to get a sense of how many parameters it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "latent_size = 100\n",
    "model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Train the model\n",
    "We are now able to train the model we created. We will train using the `MSELoss()` for $20$ epochs, using a learning rate of $0.001$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "lr = 1e-3\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = ...\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting Epoch {epoch}')\n",
    "    \n",
    "    # training phase\n",
    "    ...\n",
    "    net_loss = 0.0\n",
    "    n_total = 0\n",
    "    for x, _ in tqdm(train_dl):\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # pass the data through the model\n",
    "        out = ...\n",
    "        loss = ...\n",
    "        \n",
    "        # backpropagate\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "        \n",
    "        # keep loss statistics\n",
    "        net_loss += loss.item() * len(x)\n",
    "        n_total += len(x)\n",
    "    train_loss = net_loss / n_total\n",
    "\n",
    "    # evaluation phase\n",
    "    ...\n",
    "    net_loss = 0.0\n",
    "    n_total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, _) in enumerate(test_dl):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # pass the data through the model\n",
    "            out = ...\n",
    "            loss = ...\n",
    "            \n",
    "            # keep loss statistics\n",
    "            net_loss += loss.item() * len(x)\n",
    "            n_total += len(x)\n",
    "        test_loss = net_loss / n_total\n",
    "    print(f'Epoch {epoch}:\\t Train Loss: {train_loss:.3f}\\t Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Visualize the ouputs\n",
    "We have now trained our model and we are able to visualize its various outputs. We will focus on three things:\n",
    "- We want to visualize the filters/weights that the network is learning.\n",
    "- We want to visualize the latent representations of the data.\n",
    "- We want to visualize the reconstruction, to make sure the network is working.\n",
    "\n",
    "Fill in the code in the following three cells to generate the corresponding visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weights\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize latents\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "model_enc = ...\n",
    "indexes_test = ...\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize reconstructions\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "model_test = ...\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Compare reconstructions with those of PCA\n",
    "Since autoencoders are unsupervised techniques that can help in dimensionality reduction, it is natural to compare them with PCA. Run PCA below using `scikit-learn` and plot the reconstructions in order to compare them with the reconstructions of our autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run PCA on the training data\n",
    "pca = ...\n",
    "pca.fit(X_tr)\n",
    "\n",
    "# evaluate on the test data\n",
    "pca_test = ...\n",
    "inv_test = ...\n",
    "\n",
    "# plot the reconstructions\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that _linear_ autoencoders learn the principal components of the data, and are equivalent with PCA. In the following, we will start experimenting with _nonlinear_ autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Nonlinear autoencoders\n",
    "Since linear autoencoders are learning the principal components of the data, we will introduce nonlinearities to allow our models to be more expressive.\n",
    "\n",
    "### 2.1 Create the `NonLinearAutoencoder` class\n",
    "In the next cell, fill in the code for the nonlinear autoencoder.\n",
    "\n",
    "**Note**: feel free to experiment with other nonlinearities (e.g. `PReLU`, `tanh`, `sigmoid` or others from [torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html)) and report your findings. Do all of them work equally well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NonLinearAutoencoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        latent_size,\n",
    "    ):\n",
    "        super(NonLinearAutoencoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.latent_size = latent_size\n",
    "    \n",
    "        # create the encoder and the decoder\n",
    "        self.encoder = ...\n",
    "        self.decoder = ...\n",
    "            \n",
    "    def forward(self, data):\n",
    "        # encode the input to the latent space\n",
    "        latent = ...\n",
    "        \n",
    "        # decode the latent representation back into the input space\n",
    "        recons = ...\n",
    "        \n",
    "        # output the latent representation too so we can use it for sparsity\n",
    "        return recons, latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create the model\n",
    "Create now an model from the `NonLinearAutoencoder` class and print it's summary. Since the only thing we changed is that we added nonlinearities, we expect the number of parameters to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "latent_size = 100\n",
    "model2 = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train the model\n",
    "Let's now train the model using the same parameters as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "lr = 1e-3\n",
    "\n",
    "opt = torch.optim.Adam(model2.parameters(), lr=lr)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting Epoch {epoch}')\n",
    "    \n",
    "    # training phase\n",
    "    ...\n",
    "    net_loss = 0.0\n",
    "    n_total = 0\n",
    "    for x, y in tqdm(train_dl):\n",
    "        x = x.to(device)\n",
    "\n",
    "        # pass the data through the model\n",
    "        out, _ = ...\n",
    "        loss = ...\n",
    "        \n",
    "        # backpropagate\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "        \n",
    "        # keep loss statistics\n",
    "        net_loss += loss.item() * len(x)\n",
    "        n_total += len(x)\n",
    "    train_loss = net_loss / n_total\n",
    "\n",
    "    # evaluation phase\n",
    "    ...\n",
    "    net_loss = 0.0\n",
    "    n_total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, _) in enumerate(test_dl):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # pass the data through the model\n",
    "            out, _ = ...\n",
    "            loss = ...\n",
    "            \n",
    "            # keep loss statistics\n",
    "            net_loss += loss.item() * len(x)\n",
    "            n_total += len(x)\n",
    "        test_loss = net_loss / n_total\n",
    "    print(f'Epoch {epoch}:\\t Train Loss: {train_loss:.3f}\\t Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualize the ouputs\n",
    "As before, let's visualize the weights, latent representations, and reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weights\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize latents\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "_, model_test = ...\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize reconstructions\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "model_test, _ = ...\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our latent representations look a bit sparser than before, but the weights the network is learning are still not very interpretable. Let's try adding sparsity on the codes in order to enforce the autoencoder to learn more interpretable features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Train with a sparse objective\n",
    "Modify your training procedure from before to include a sparsity penalty. Set the regularization parameter `lam = 0.00125`.\n",
    "\n",
    "**Note**: feel free to experiment with different values of `lam`. How does increasing this parameter affects the latent representations and the weights? What about decreasing it? Are the reconstructions still acceptable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "lr = 1e-3\n",
    "lam = 0.00125\n",
    "\n",
    "model2 = NonLinearAutoencoder(input_size, latent_size).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model2.parameters(), lr=lr)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting Epoch {epoch}')\n",
    "    \n",
    "    # training phase\n",
    "    ...\n",
    "    net_loss = 0.0\n",
    "    n_total = 0\n",
    "    for x, _ in tqdm(train_dl):\n",
    "        x = x.to(device)\n",
    "\n",
    "        # pass the data through the model\n",
    "        out, code = ...\n",
    "        loss = ...\n",
    "        \n",
    "        # backpropagate\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "        \n",
    "        # keep loss statistics\n",
    "        net_loss += loss.item() * len(x)\n",
    "        n_total += len(x)\n",
    "    train_loss = net_loss / n_total\n",
    "\n",
    "    # evaluation phase\n",
    "    ...\n",
    "    net_loss = 0.0\n",
    "    n_total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, _) in enumerate(test_dl):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # pass the data through the model\n",
    "            out, code = ...\n",
    "            loss = ...\n",
    "            \n",
    "            # keep loss statistics\n",
    "            net_loss += loss.item() * len(x)\n",
    "            n_total += len(x)\n",
    "        test_loss = net_loss / n_total\n",
    "    print(f'Epoch {epoch}:\\t Train Loss: {train_loss:.3f}\\t Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Visualize the outputs\n",
    "As before, visualize the outputs of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weights\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize latents\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "_, model_test = ...\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize reconstructions\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "model_test, _ = ...\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the latent representations are significantly sparser now and the filters are starting to look a little bit more like digits, and the reconstructions are still reasonable. For the final part, let's make a deep autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Deep autoencoders\n",
    "Let's examine how the depth of the autoencoder affects\n",
    "\n",
    "### 3.1 Create the `DeepAutoencoder` class\n",
    "In the next cell, fill in the code for the deep autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DeepAutoencoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        firstlayer_size,\n",
    "        seconlayer_size,\n",
    "        thirdlayer_size,\n",
    "    ):\n",
    "        super(DeepAutoencoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.firstlayer_size = firstlayer_size\n",
    "        self.seconlayer_size = seconlayer_size\n",
    "        self.thirdlayer_size = thirdlayer_size\n",
    "    \n",
    "        # create the encoder and the decoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            ...\n",
    "            nn.ReLU(),\n",
    "            ...\n",
    "            nn.ReLU(),\n",
    "            ...\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            ...\n",
    "            nn.ReLU(),\n",
    "            ...\n",
    "            nn.ReLU(),\n",
    "            ...\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "            \n",
    "    def forward(self, data):\n",
    "        # encode the input to the latent space\n",
    "        latent = ...\n",
    "        \n",
    "        # decode the latent representation back into the input space\n",
    "        recons = ...\n",
    "        \n",
    "        # output the latent representation too so we can use it for sparsity\n",
    "        return recons, latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train with a sparse objective\n",
    "We will train the deep autoencoder directly using a sparse objective. Create a model from the `DeepAutoencoder` class with $400$, $200$, and $100$ sizes for the intermediate layers. Set the regularization parameter `lam = 0.00005` and use the same parameters as before for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "lr = 1e-3\n",
    "lam = 0.00005\n",
    "\n",
    "input_size = 784\n",
    "firstlayer_size = 400\n",
    "seconlayer_size = 200\n",
    "thirdlayer_size = 100\n",
    "model3 = ...\n",
    "\n",
    "opt = torch.optim.Adam(model3.parameters(), lr=lr)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting Epoch {epoch}')\n",
    "    \n",
    "    # training phase\n",
    "    ...\n",
    "    net_loss = 0.0\n",
    "    n_total = 0\n",
    "    for x, _ in tqdm(train_dl):\n",
    "        x = x.to(device)\n",
    "\n",
    "        # pass the data through the model\n",
    "        out, code = ...\n",
    "        loss = ...\n",
    "        \n",
    "        # backpropagate\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "\n",
    "        # keep loss statistics\n",
    "        net_loss += loss.item() * len(x)\n",
    "        n_total += len(x)\n",
    "    train_loss = net_loss / n_total\n",
    "\n",
    "    # evaluation phase\n",
    "    ...\n",
    "    net_loss = 0.0\n",
    "    n_total = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, _) in enumerate(test_dl):\n",
    "            x = x.to(device)\n",
    "\n",
    "            # pass the data through the model\n",
    "            out, code = ...\n",
    "            loss = ...\n",
    "            \n",
    "            # keep loss statistics\n",
    "            net_loss += loss.item() * len(x)\n",
    "            n_total += len(x)\n",
    "        test_loss = net_loss / n_total\n",
    "    print(f'Epoch {epoch}:\\t Train Loss: {train_loss:.3f}\\t Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualize the ouputs\n",
    "As before, let's visualize the weights, latent representations, and reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize weights\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "weights = ...\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize latents\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "_, model_test = ...\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize reconstructions\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8,8))\n",
    "model_test, _ = ...\n",
    "\n",
    "idx = 0\n",
    "for row in axes:\n",
    "    for col in row:\n",
    "        img = ...\n",
    "        col.imshow(img)\n",
    "        col.axis(\"off\")\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the weights that we are learning right now look more aggresively like digits (albeit, still, very noisy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we learned about training autoencoders, and we examined different trade-offs as we are adding nonlinearities, sparsity, and depth."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
